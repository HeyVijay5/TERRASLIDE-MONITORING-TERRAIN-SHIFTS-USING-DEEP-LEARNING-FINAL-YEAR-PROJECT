{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNZ4ep8UpDsvf/KbMvEX8cm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeyVijay5/HeyVijay5-TERRASLIDE---MONITORING-TERRAIN-SHIFTS-USING-DEEP-LEARNING/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beIde9doXvPK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader\n",
        "import h5py\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CtPmtKLYPhp",
        "outputId": "1615049d-815c-4677-94bb-b2686cb6f1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/My Drive/TrainData/your_dataset.zip\"\n",
        "\n"
      ],
      "metadata": {
        "id": "oCdzgwrvYwNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/My Drive/TrainData/your_model.pth\""
      ],
      "metadata": {
        "id": "OZ9xVDMxZAbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/My\\ Drive/your_folder/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAD7_k9YZhcS",
        "outputId": "42986861-ac6e-403e-8230-cd347b917343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/My Drive/your_folder/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class LandslideDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n"
      ],
      "metadata": {
        "id": "zAC72iacZp7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/SDP FILES\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN0oYV2abola",
        "outputId": "1c715a81-83d9-47fb-c359-fc1d3e23b613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TestData  TrainData  ValidData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/content/drive/My Drive/SDP FILES/TrainData\"\n",
        "test_path = \"/content/drive/My Drive/SDP FILES/TestData\"\n",
        "valid_path = \"/content/drive/My Drive/SDP FILES/ValidData\"\n"
      ],
      "metadata": {
        "id": "7fd2v-_8buCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/SDP FILES/TrainData\"\n",
        "!ls \"/content/drive/My Drive/SDP FILES/TestData\"\n",
        "!ls \"/content/drive/My Drive/SDP FILES/ValidData\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyWRCg3qbvFU",
        "outputId": "eeac6ee7-fb00-4951-9fbe-2393b9e49e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img  mask\n",
            "img  mask\n",
            "img  mask\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class LandslideDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
        "\n",
        "        # Print debug info\n",
        "        print(f\"Loaded {len(self.image_files)} images from {root_dir}\")\n",
        "\n",
        "        if len(self.image_files) == 0:\n",
        "            raise ValueError(f\"No image files found in {root_dir}. Check the path!\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n"
      ],
      "metadata": {
        "id": "hbyJYhk3bytK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/SDP FILES/TrainData\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ergKtu-mcFPQ",
        "outputId": "cca9f44b-f46a-4230-f762-ee987eaeeda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img  mask\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_path = \"/content/drive/My Drive/SDP FILES/TrainData\"\n",
        "print(\"Files in TrainData:\", os.listdir(train_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eis7B-v9cGsa",
        "outputId": "d9661f4a-3ec9-4932-f0f1-0de1cf83f105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in TrainData: ['img', 'mask']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class LandslideDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Define image and mask paths\n",
        "        self.image_dir = os.path.join(root_dir, \"images\")\n",
        "        self.mask_dir = os.path.join(root_dir, \"masks\")\n",
        "\n",
        "        # Get sorted lists of image and mask files (assuming same filenames)\n",
        "        self.image_files = sorted([f for f in os.listdir(self.image_dir) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))])\n",
        "        self.mask_files = sorted([f for f in os.listdir(self.mask_dir) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))])\n",
        "\n",
        "        if len(self.image_files) == 0:\n",
        "            raise ValueError(f\"No image files found in {self.image_dir}. Check the path!\")\n",
        "\n",
        "        if len(self.mask_files) == 0:\n",
        "            raise ValueError(f\"No mask files found in {self.mask_dir}. Check the path!\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
        "\n",
        "        # Open images and masks\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")  # Convert mask to grayscale\n",
        "\n",
        "        # Apply transformations (if any)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return image, mask\n"
      ],
      "metadata": {
        "id": "GEkHaQm5cu8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/SDP FILES/TrainData\"\n",
        "!ls \"/content/drive/My Drive/SDP FILES/TrainData/images\"\n",
        "!ls \"/content/drive/My Drive/SDP FILES/TrainData/masks\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2W-cfOAc3No",
        "outputId": "8fd415eb-1263-49c8-85e2-9eaece00e94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img  mask\n",
            "ls: cannot access '/content/drive/My Drive/SDP FILES/TrainData/images': No such file or directory\n",
            "ls: cannot access '/content/drive/My Drive/SDP FILES/TrainData/masks': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install h5py torch torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi5YAJq-dm7q",
        "outputId": "3d5835ef-4873-4043-c128-61f2eb75b52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.12.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from h5py) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import h5py\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "class H5LandslideDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the '.h5' files.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on an image sample.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = sorted([f for f in os.listdir(root_dir) if f.startswith('image_') and f.endswith('.h5')])\n",
        "        self.mask_files = sorted([f for f in os.listdir(root_dir) if f.startswith('mask_') and f.endswith('.h5')])\n",
        "\n",
        "        if len(self.image_files) == 0:\n",
        "            raise ValueError(f\"No image files found in {root_dir}. Check the path!\")\n",
        "\n",
        "        if len(self.mask_files) == 0:\n",
        "            raise ValueError(f\"No mask files found in {root_dir}. Check the path!\")\n",
        "\n",
        "        if len(self.image_files) != len(self.mask_files):\n",
        "            raise ValueError(\"The number of images and masks do not match.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
        "        mask_name = os.path.join(self.root_dir, self.mask_files[idx])\n",
        "\n",
        "        with h5py.File(img_name, 'r') as img_file:\n",
        "            image = img_file['dataset'][:]\n",
        "        with h5py.File(mask_name, 'r') as mask_file:\n",
        "            mask = mask_file['dataset'][:]\n",
        "\n",
        "        # Convert numpy arrays to PIL Images\n",
        "        image = transforms.ToPILImage()(image)\n",
        "        mask = transforms.ToPILImage()(mask)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return image, mask\n"
      ],
      "metadata": {
        "id": "3qefq-D5eLNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = '/content/drive/My Drive/SDP FILES/TrainData'\n",
        "\n"
      ],
      "metadata": {
        "id": "z4FJY4EpeWQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if os.path.exists(train_data_path):\n",
        "    print(\"Directory exists. Contents:\")\n",
        "    print(os.listdir(train_data_path))\n",
        "else:\n",
        "    print(\"Directory does not exist. Please check the path.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SIFA5SDebgp",
        "outputId": "f1bb7e3b-8402-47b8-b7e4-f5b99ceea77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory exists. Contents:\n",
            "['img', 'mask']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LandslideDataSet(data.Dataset):\n",
        "    def __init__(self, data_dir, list_path, max_iters=None,set='label'):\n",
        "        self.list_path = list_path\n",
        "        self.mean = [-0.4914, -0.3074, -0.1277, -0.0625, 0.0439, 0.0803, 0.0644, 0.0802, 0.3000, 0.4082, 0.0823, 0.0516, 0.3338, 0.7819]\n",
        "        self.std = [0.9325, 0.8775, 0.8860, 0.8869, 0.8857, 0.8418, 0.8354, 0.8491, 0.9061, 1.6072, 0.8848, 0.9232, 0.9018, 1.2913]\n",
        "        self.set = set\n",
        "        self.img_ids = [i_id.strip() for i_id in open(list_path)]\n",
        "\n",
        "        if not max_iters==None:\n",
        "            n_repeat = int(np.ceil(max_iters / len(self.img_ids)))\n",
        "            self.img_ids = self.img_ids * n_repeat + self.img_ids[:max_iters-n_repeat*len(self.img_ids)]\n",
        "\n",
        "        self.files = []\n",
        "\n",
        "        if set=='labeled':\n",
        "            for name in self.img_ids:\n",
        "                img_file = data_dir + name\n",
        "                label_file = data_dir + name.replace('img','mask').replace('image','mask')\n",
        "                self.files.append({\n",
        "                    'img': img_file,\n",
        "                    'label': label_file,\n",
        "                    'name': name\n",
        "                })\n",
        "        elif set=='unlabeled':\n",
        "            for name in self.img_ids:\n",
        "                img_file = data_dir + name\n",
        "                self.files.append({\n",
        "                    'img': img_file,\n",
        "                    'name': name\n",
        "                })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KpoV1hOSevbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LandslideDataSet(data.Dataset):\n",
        "    def __init__(self, data_dir, list_path, max_iters=None,set='label'):\n",
        "        self.list_path = list_path\n",
        "        self.mean = [-0.4914, -0.3074, -0.1277, -0.0625, 0.0439, 0.0803, 0.0644, 0.0802, 0.3000, 0.4082, 0.0823, 0.0516, 0.3338, 0.7819]\n",
        "        self.std = [0.9325, 0.8775, 0.8860, 0.8869, 0.8857, 0.8418, 0.8354, 0.8491, 0.9061, 1.6072, 0.8848, 0.9232, 0.9018, 1.2913]\n",
        "        self.set = set\n",
        "        self.img_ids = [i_id.strip() for i_id in open(list_path)]\n",
        "\n",
        "        if not max_iters==None:\n",
        "            n_repeat = int(np.ceil(max_iters / len(self.img_ids)))\n",
        "            self.img_ids = self.img_ids * n_repeat + self.img_ids[:max_iters-n_repeat*len(self.img_ids)]\n",
        "\n",
        "        self.files = []\n",
        "\n",
        "        if set=='labeled':\n",
        "            for name in self.img_ids:\n",
        "                img_file = data_dir + name\n",
        "                label_file = data_dir + name.replace('img','mask').replace('image','mask')\n",
        "                self.files.append({\n",
        "                    'img': img_file,\n",
        "                    'label': label_file,\n",
        "                    'name': name\n",
        "                })\n",
        "        elif set=='unlabeled':\n",
        "            for name in self.img_ids:\n",
        "                img_file = data_dir + name\n",
        "                self.files.append({\n",
        "                    'img': img_file,\n",
        "                    'name': name\n",
        "                })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cb_liXixe0Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Networks.py"
      ],
      "metadata": {
        "id": "6tiK_XOze8PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "xwxQo0uGe9T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)"
      ],
      "metadata": {
        "id": "2lQ6RqnzfFZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Down(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n"
      ],
      "metadata": {
        "id": "8NooJ9r9fHyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Up(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n"
      ],
      "metadata": {
        "id": "MStaHFDbfKIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n"
      ],
      "metadata": {
        "id": "9a5lqxiBfMqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class unet(nn.Module):\n",
        "    def __init__(self, n_classes, n_channels=14, bilinear=True):\n",
        "        super(unet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "qi_7NDTJfPhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tools.py"
      ],
      "metadata": {
        "id": "-5jUHzJCfU8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "3fhEXtULfbYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_image(predict,label,num_classes):\n",
        "    index = np.where((label>=0) & (label<num_classes))\n",
        "    predict = predict[index]\n",
        "    label = label[index]\n",
        "\n",
        "    TP = np.zeros((num_classes, 1))\n",
        "    FP = np.zeros((num_classes, 1))\n",
        "    TN = np.zeros((num_classes, 1))\n",
        "    FN = np.zeros((num_classes, 1))\n",
        "\n",
        "    for i in range(0,num_classes):\n",
        "        TP[i] = np.sum(label[np.where(predict==i)]==i)\n",
        "        FP[i] = np.sum(label[np.where(predict==i)]!=i)\n",
        "        TN[i] = np.sum(label[np.where(predict!=i)]!=i)\n",
        "        FN[i] = np.sum(label[np.where(predict!=i)]==i)\n",
        "\n",
        "    return TP,FP,TN,FN,len(label)"
      ],
      "metadata": {
        "id": "jLthrI3zfdpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n1-NFGtgfftz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict.py"
      ],
      "metadata": {
        "id": "Gw0OS2nefixK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import h5py\n"
      ],
      "metadata": {
        "id": "7OgAC3mJfm1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name_classes = ['Non-Landslide','Landslide']\n",
        "epsilon = 1e-14"
      ],
      "metadata": {
        "id": "p8L8UTbHgrNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def importName(modulename, name):\n",
        "    \"\"\" Import a named object from a module in the context of this function.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        module = __import__(modulename, globals(), locals(  ), [name])\n",
        "    except ImportError:\n",
        "        return None\n",
        "    return vars(module)[name]\n"
      ],
      "metadata": {
        "id": "LS4wJOl9gubh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_arguments():\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Baseline method for Land4Seen\")\n",
        "\n",
        "    parser.add_argument(\"--data_dir\", type=str, default='/scratch/Land4Sense_Competition_h5/',\n",
        "                        help=\"dataset path.\")\n",
        "    parser.add_argument(\"--model_module\", type =str, default='model.Networks',\n",
        "                        help='model module to import')\n",
        "    parser.add_argument(\"--model_name\", type=str, default='unet',\n",
        "                        help='modle name in given module')\n",
        "    parser.add_argument(\"--test_list\", type=str, default='./dataset/test.txt',\n",
        "                        help=\"test list file.\")\n",
        "    parser.add_argument(\"--input_size\", type=str, default='128,128',\n",
        "                        help=\"width and height of input images.\")\n",
        "    parser.add_argument(\"--num_classes\", type=int, default=2,\n",
        "                        help=\"number of classes.\")\n",
        "    parser.add_argument(\"--num_workers\", type=int, default=0,\n",
        "                        help=\"number of workers for multithread dataloading.\")\n",
        "    parser.add_argument(\"--gpu_id\", type=int, default=0,\n",
        "                        help=\"gpu id in the training.\")\n",
        "    parser.add_argument(\"--snapshot_dir\", type=str, default='./test_map/',\n",
        "                        help=\"where to save predicted maps.\")\n",
        "    parser.add_argument(\"--restore_from\", type=str, default='./exp/batch3500_F1_7396.pth',\n",
        "                        help=\"trained model.\")\n",
        "\n",
        "    return parser.parse_args()\n"
      ],
      "metadata": {
        "id": "2YoQZ0VKgwpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    args = get_arguments()\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
        "    snapshot_dir = args.snapshot_dir\n",
        "    if os.path.exists(snapshot_dir)==False:\n",
        "        os.makedirs(snapshot_dir)\n",
        "\n",
        "    w, h = map(int, args.input_size.split(','))\n",
        "    input_size = (w, h)\n",
        "\n",
        "    cudnn.enabled = True\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # Create network\n",
        "    model = unet(n_classes=args.num_classes)\n",
        "\n",
        "    saved_state_dict = torch.load(args.restore_from)\n",
        "    model.load_state_dict(saved_state_dict)\n",
        "\n",
        "    model = model.cuda()\n",
        "\n",
        "    test_loader = data.DataLoader(\n",
        "                    LandslideDataSet(args.data_dir, args.test_list, set='unlabeled'),\n",
        "                    batch_size=1, shuffle=False, num_workers=args.num_workers, pin_memory=True)\n",
        "\n",
        "\n",
        "    interp = nn.Upsample(size=(input_size[1], input_size[0]), mode='bilinear')\n",
        "\n",
        "\n",
        "    print('Testing..........')\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    for index, batch in enumerate(test_loader):\n",
        "        image, _, name = batch\n",
        "        image = image.float().cuda()\n",
        "        name = name[0].split('.')[0].split('/')[-1].replace('image','mask')\n",
        "        print(index+1, '/', len(test_loader), ': Testing ', name)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(image)\n",
        "\n",
        "        _,pred = torch.max(interp(nn.functional.softmax(pred,dim=1)).detach(), 1)\n",
        "        pred = pred.squeeze().data.cpu().numpy().astype('uint8')\n",
        "        with h5py.File(snapshot_dir+name+'.h5','w') as hf:\n",
        "            hf.create_dataset('mask', data=pred)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "dIt51kDug0lo",
        "outputId": "649c2a5e-b18c-4cae-9456-0c744cd60cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--data_dir DATA_DIR] [--model_module MODEL_MODULE]\n",
            "                                [--model_name MODEL_NAME] [--test_list TEST_LIST]\n",
            "                                [--input_size INPUT_SIZE] [--num_classes NUM_CLASSES]\n",
            "                                [--num_workers NUM_WORKERS] [--gpu_id GPU_ID]\n",
            "                                [--snapshot_dir SNAPSHOT_DIR] [--restore_from RESTORE_FROM]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-464ea338-2464-481c-813c-99794f2fb722.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "def get_arguments():\n",
        "    parser = argparse.ArgumentParser(description=\"Your script description\")\n",
        "    # Define your arguments here\n",
        "    # e.g., parser.add_argument('--data_dir', type=str, required=True, help='Path to data directory')\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    return args\n"
      ],
      "metadata": {
        "id": "UwmxUJfPhGLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import argparse\n",
        "\n",
        "sys.argv = ['']  # or sys.argv = ['your_script_name.py', '--arg1', 'value1']\n",
        "\n",
        "def get_arguments():\n",
        "    parser = argparse.ArgumentParser(description=\"Your script description\")\n",
        "    # Define your arguments here\n",
        "    args = parser.parse_args()\n",
        "    return args\n"
      ],
      "metadata": {
        "id": "Qg7yXkhfhHWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters directly\n",
        "data_dir = '/path/to/data'\n",
        "model_module = 'model_name'\n",
        "# Add other parameters as needed\n"
      ],
      "metadata": {
        "id": "Zh7-qpMRhMaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "def get_arguments():\n",
        "    parser = argparse.ArgumentParser(description=\"Your script description\")\n",
        "    # Define your arguments here\n",
        "    return parser.parse_args()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = get_arguments()\n",
        "    # Call your main function or script logic here\n"
      ],
      "metadata": {
        "id": "7IJ2N29GhPvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    args = get_arguments()\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
        "    snapshot_dir = args.snapshot_dir\n",
        "    if os.path.exists(snapshot_dir)==False:\n",
        "        os.makedirs(snapshot_dir)\n",
        "\n",
        "    w, h = map(int, args.input_size.split(','))\n",
        "    input_size = (w, h)\n",
        "\n",
        "    cudnn.enabled = True\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # Create network\n",
        "    model = unet(n_classes=args.num_classes)\n",
        "\n",
        "    saved_state_dict = torch.load(args.restore_from)\n",
        "    model.load_state_dict(saved_state_dict)\n",
        "\n",
        "    model = model.cuda()\n",
        "\n",
        "    test_loader = data.DataLoader(\n",
        "                    LandslideDataSet(args.data_dir, args.test_list, set='unlabeled'),\n",
        "                    batch_size=1, shuffle=False, num_workers=args.num_workers, pin_memory=True)\n",
        "\n",
        "\n",
        "    interp = nn.Upsample(size=(input_size[1], input_size[0]), mode='bilinear')\n",
        "\n",
        "\n",
        "    print('Testing..........')\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    for index, batch in enumerate(test_loader):\n",
        "        image, _, name = batch\n",
        "        image = image.float().cuda()\n",
        "        name = name[0].split('.')[0].split('/')[-1].replace('image','mask')\n",
        "        print(index+1, '/', len(test_loader), ': Testing ', name)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(image)\n",
        "\n",
        "        _,pred = torch.max(interp(nn.functional.softmax(pred,dim=1)).detach(), 1)\n",
        "        pred = pred.squeeze().data.cpu().numpy().astype('uint8')\n",
        "        with h5py.File(snapshot_dir+name+'.h5','w') as hf:\n",
        "            hf.create_dataset('mask', data=pred)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "yCX7Lbx9hUfr",
        "outputId": "1dd56835-20a8-47d2-b414-8c15a25af268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Namespace' object has no attribute 'gpu_id'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-410b73e45bab>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-410b73e45bab>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msnapshot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnapshot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnapshot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'gpu_id'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "def get_arguments():\n",
        "    parser = argparse.ArgumentParser(description=\"Your script description\")\n",
        "    # Other argument definitions...\n",
        "    parser.add_argument('--gpu_id', type=int, default=0, help='ID of the GPU to use')\n",
        "    return parser.parse_args()\n"
      ],
      "metadata": {
        "id": "agXk_i4_hhSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    gpu_id = 0\n",
        "    # Define other arguments as needed\n",
        "\n",
        "args = Args()\n"
      ],
      "metadata": {
        "id": "yThpSrBKhiUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    args = get_arguments()\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
        "    snapshot_dir = args.snapshot_dir\n",
        "    if os.path.exists(snapshot_dir)==False:\n",
        "        os.makedirs(snapshot_dir)\n",
        "\n",
        "    w, h = map(int, args.input_size.split(','))\n",
        "    input_size = (w, h)\n",
        "\n",
        "    cudnn.enabled = True\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # Create network\n",
        "    model = unet(n_classes=args.num_classes)\n",
        "\n",
        "    saved_state_dict = torch.load(args.restore_from)\n",
        "    model.load_state_dict(saved_state_dict)\n",
        "\n",
        "    model = model.cuda()\n",
        "\n",
        "    test_loader = data.DataLoader(\n",
        "                    LandslideDataSet(args.data_dir, args.test_list, set='unlabeled'),\n",
        "                    batch_size=1, shuffle=False, num_workers=args.num_workers, pin_memory=True)\n",
        "\n",
        "\n",
        "    interp = nn.Upsample(size=(input_size[1], input_size[0]), mode='bilinear')\n",
        "\n",
        "\n",
        "    print('Testing..........')\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    for index, batch in enumerate(test_loader):\n",
        "        image, _, name = batch\n",
        "        image = image.float().cuda()\n",
        "        name = name[0].split('.')[0].split('/')[-1].replace('image','mask')\n",
        "        print(index+1, '/', len(test_loader), ': Testing ', name)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(image)\n",
        "\n",
        "        _,pred = torch.max(interp(nn.functional.softmax(pred,dim=1)).detach(), 1)\n",
        "        pred = pred.squeeze().data.cpu().numpy().astype('uint8')\n",
        "        with h5py.File(snapshot_dir+name+'.h5','w') as hf:\n",
        "            hf.create_dataset('mask', data=pred)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Y4PlqEBzhmBo",
        "outputId": "f98b5c7f-fb55-4d68-dc4c-7d8ee09c736c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Namespace' object has no attribute 'snapshot_dir'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-410b73e45bab>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-410b73e45bab>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msnapshot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnapshot_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnapshot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnapshot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'snapshot_dir'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAIN\n"
      ],
      "metadata": {
        "id": "hDgghCFRgmVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "import importlib"
      ],
      "metadata": {
        "id": "8uFvWCmrgOEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "name_classes = ['Non-Landslide','Landslide']\n",
        "epsilon = 1e-14\n"
      ],
      "metadata": {
        "id": "EMzOH7dwhnzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def importName(modulename, name):\n",
        "    \"\"\" Import a named object from a module in the context of this function.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        module = __import__(modulename, globals(), locals(  ), [name])\n",
        "    except ImportError:\n",
        "        return None\n",
        "    return vars(module)[name]\n"
      ],
      "metadata": {
        "id": "wecAVon_hrqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_arguments():\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Baseline method for Land4Seen\")\n",
        "\n",
        "    parser.add_argument(\"--data_dir\", type=str, default='/scratch/Land4Sense_Competition_h5/',\n",
        "                        help=\"dataset path.\")\n",
        "    parser.add_argument(\"--model_module\", type =str, default='model.Networks',\n",
        "                        help='model module to import')\n",
        "    parser.add_argument(\"--model_name\", type=str, default='unet',\n",
        "                        help='modle name in given module')\n",
        "    parser.add_argument(\"--train_list\", type=str, default='./dataset/train.txt',\n",
        "                        help=\"training list file.\")\n",
        "    parser.add_argument(\"--test_list\", type=str, default='./dataset/train.txt',\n",
        "                        help=\"test list file.\")\n",
        "    parser.add_argument(\"--input_size\", type=str, default='128,128',\n",
        "                        help=\"width and height of input images.\")\n",
        "    parser.add_argument(\"--num_classes\", type=int, default=2,\n",
        "                        help=\"number of classes.\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=32,\n",
        "                        help=\"number of images in each batch.\")\n",
        "    parser.add_argument(\"--num_workers\", type=int, default=4,\n",
        "                        help=\"number of workers for multithread dataloading.\")\n",
        "    parser.add_argument(\"--learning_rate\", type=float, default=1e-3,\n",
        "                        help=\"learning rate.\")\n",
        "    parser.add_argument(\"--num_steps\", type=int, default=5000,\n",
        "                        help=\"number of training steps.\")\n",
        "    parser.add_argument(\"--num_steps_stop\", type=int, default=5000,\n",
        "                        help=\"number of training steps for early stopping.\")\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=5e-4,\n",
        "                        help=\"regularisation parameter for L2-loss.\")\n",
        "    parser.add_argument(\"--gpu_id\", type=int, default=0,\n",
        "                        help=\"gpu id in the training.\")\n",
        "    parser.add_argument(\"--snapshot_dir\", type=str, default='./exp/',\n",
        "                        help=\"where to save snapshots of the model.\")\n",
        "\n",
        "    return parser.parse_args()\n"
      ],
      "metadata": {
        "id": "CBNVhPGjht3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    args = get_arguments()\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
        "    snapshot_dir = args.snapshot_dir\n",
        "    if os.path.exists(snapshot_dir)==False:\n",
        "        os.makedirs(snapshot_dir)\n",
        "\n",
        "    w, h = map(int, args.input_size.split(','))\n",
        "    input_size = (w, h)\n",
        "\n",
        "    cudnn.enabled = True\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    # Create network\n",
        "    model_import = importName(args.model_module, args.model_name)\n",
        "    model = model_import(n_classes=args.num_classes)\n",
        "    model.train()\n",
        "    model = model.cuda()\n",
        "\n",
        "    src_loader = data.DataLoader(\n",
        "                    LandslideDataSet(args.data_dir, args.train_list, max_iters=args.num_steps_stop*args.batch_size,set='labeled'),\n",
        "                    batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n",
        "\n",
        "\n",
        "    test_loader = data.DataLoader(\n",
        "                    LandslideDataSet(args.data_dir, args.train_list,set='labeled'),\n",
        "                    batch_size=1, shuffle=False, num_workers=args.num_workers, pin_memory=True)\n",
        "\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                        lr=args.learning_rate, weight_decay=args.weight_decay)\n",
        "\n",
        "    interp = nn.Upsample(size=(input_size[1], input_size[0]), mode='bilinear')\n",
        "\n",
        "    hist = np.zeros((args.num_steps_stop,3))\n",
        "    F1_best = 0.5\n",
        "    cross_entropy_loss = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "    for batch_id, src_data in enumerate(src_loader):\n",
        "        if batch_id==args.num_steps_stop:\n",
        "            break\n",
        "        tem_time = time.time()\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        images, labels, _, _ = src_data\n",
        "        images = images.cuda()\n",
        "        pred = model(images)\n",
        "\n",
        "        pred_interp = interp(pred)\n",
        "\n",
        "        # CE Loss\n",
        "        labels = labels.cuda().long()\n",
        "        cross_entropy_loss_value = cross_entropy_loss(pred_interp, labels)\n",
        "        _, predict_labels = torch.max(pred_interp, 1)\n",
        "        predict_labels = predict_labels.detach().cpu().numpy()\n",
        "        labels = labels.cpu().numpy()\n",
        "        batch_oa = np.sum(predict_labels==labels)*1./len(labels.reshape(-1))\n",
        "\n",
        "\n",
        "        hist[batch_id,0] = cross_entropy_loss_value.item()\n",
        "        hist[batch_id,1] = batch_oa\n",
        "\n",
        "        cross_entropy_loss_value.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        hist[batch_id,-1] = time.time() - tem_time\n",
        "\n",
        "        if (batch_id+1) % 10 == 0:\n",
        "            print('Iter %d/%d Time: %.2f Batch_OA = %.1f cross_entropy_loss = %.3f'%(batch_id+1,args.num_steps,10*np.mean(hist[batch_id-9:batch_id+1,-1]),np.mean(hist[batch_id-9:batch_id+1,1])*100,np.mean(hist[batch_id-9:batch_id+1,0])))\n",
        "\n",
        "        # evaluation per 500 iterations\n",
        "        if (batch_id+1) % 500 == 0:\n",
        "            print('Testing..........')\n",
        "            model.eval()\n",
        "            TP_all = np.zeros((args.num_classes, 1))\n",
        "            FP_all = np.zeros((args.num_classes, 1))\n",
        "            TN_all = np.zeros((args.num_classes, 1))\n",
        "            FN_all = np.zeros((args.num_classes, 1))\n",
        "            n_valid_sample_all = 0\n",
        "            F1 = np.zeros((args.num_classes, 1))\n",
        "\n",
        "            for _, batch in enumerate(test_loader):\n",
        "                image, label,_, name = batch\n",
        "                label = label.squeeze().numpy()\n",
        "                image = image.float().cuda()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    pred = model(image)\n",
        "\n",
        "                _,pred = torch.max(interp(nn.functional.softmax(pred,dim=1)).detach(), 1)\n",
        "                pred = pred.squeeze().data.cpu().numpy()\n",
        "\n",
        "                TP,FP,TN,FN,n_valid_sample = eval_image(pred.reshape(-1),label.reshape(-1),args.num_classes)\n",
        "                TP_all += TP\n",
        "                FP_all += FP\n",
        "                TN_all += TN\n",
        "                FN_all += FN\n",
        "                n_valid_sample_all += n_valid_sample\n",
        "\n",
        "            OA = np.sum(TP_all)*1.0 / n_valid_sample_all\n",
        "            for i in range(args.num_classes):\n",
        "                P = TP_all[i]*1.0 / (TP_all[i] + FP_all[i] + epsilon)\n",
        "                R = TP_all[i]*1.0 / (TP_all[i] + FN_all[i] + epsilon)\n",
        "                F1[i] = 2.0*P*R / (P + R + epsilon)\n",
        "                if i==1:\n",
        "                    print('===>' + name_classes[i] + ' Precision: %.2f'%(P * 100))\n",
        "                    print('===>' + name_classes[i] + ' Recall: %.2f'%(R * 100))\n",
        "                    print('===>' + name_classes[i] + ' F1: %.2f'%(F1[i] * 100))\n",
        "\n",
        "            mF1 = np.mean(F1)\n",
        "            print('===> mean F1: %.2f OA: %.2f'%(mF1*100,OA*100))\n",
        "\n",
        "            if F1[1]>F1_best:\n",
        "                F1_best = F1[1]\n",
        "                # save the models\n",
        "                print('Save Model')\n",
        "                model_name = 'batch'+repr(batch_id+1)+'_F1_'+repr(int(F1[1]*10000))+'.pth'\n",
        "                torch.save(model.state_dict(), os.path.join(\n",
        "                    snapshot_dir, model_name))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "9IGOiZplhwm_",
        "outputId": "fa46f452-9d27-4b33-8121-f95f0d7939c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: [-h] --model_module MODEL_MODULE --model_name MODEL_NAME\n",
            ": error: the following arguments are required: --model_module, --model_name\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "\n",
        "def get_arguments():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--model_module\", type=str, required=True, help=\"Module where the model is defined\")\n",
        "    parser.add_argument(\"--model_name\", type=str, required=True, help=\"Name of the model class\")\n",
        "    return parser.parse_args()\n"
      ],
      "metadata": {
        "id": "PEApntH_ii4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    model_module = \"your_model_module\"\n",
        "    model_name = \"YourModelClass\"\n",
        "\n",
        "args = Args()\n"
      ],
      "metadata": {
        "id": "nbbXSbC7jKpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "    model_module = \"args.model_module\"  # Replace with your actual model module\n",
        "    model_name = \"YourModelClass\"       # Replace with your actual model class\n",
        "\n",
        "args = Args()\n"
      ],
      "metadata": {
        "id": "CkrHCRvfjVJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from landslide_model import LandslideNet  # Change this to your actual module and class\n",
        "print(LandslideNet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "j_26gEHLj5zP",
        "outputId": "0e18b4e6-087d-4747-cc64-3b7d7c59a2f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'landslide_model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-45d0f9256cd1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlandslide_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLandslideNet\u001b[0m  \u001b[0;31m# Change this to your actual module and class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLandslideNet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'landslide_model'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEL2j3IjkfwZ",
        "outputId": "ea0731ba-6f09-4984-9a0e-5c92f37033de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'drive', 'exp', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Search for landslide_model.py in all subdirectories\n",
        "for root, dirs, files in os.walk(\"/\"):\n",
        "    if \"landslide_model.py\" in files:\n",
        "        print(\"Found:\", os.path.join(root, \"landslide_model.py\"))\n"
      ],
      "metadata": {
        "id": "DEGbQHxuku1X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}